# Engenheiro-MLOps-GCP

# Objetivo  
Avaliar o conhecimento e a experi√™ncia do candidato em MLOps com foco na Google Cloud Platform (GCP), cobrindo automa√ß√£o, orquestra√ß√£o, escalabilidade, seguran√ßa e monitoramento.  

## Se√ß√£o 1: Conceitos e Arquitetura (Quest√µes Te√≥ricas)  

### 1. Infraestrutura e Orquestra√ß√£o  
- Qual a diferen√ßa entre Vertex AI Pipelines e Kubeflow Pipelines na GCP? Quando escolher um em vez do outro?
  
# Resposta: üìå Vertex AI Pipelines vs. Kubeflow Pipelines (KFP) na GCP

## üåü Vertex AI Pipelines
‚úÖ **Gerenciado pela GCP** ‚Üí Sem necessidade de gerenciar Kubernetes  
‚úÖ **Integra√ß√£o nativa** com Vertex AI, IAM, Logging  
‚úÖ **Seguran√ßa aprimorada** com IAM  
‚úÖ **Foco no desenvolvimento** sem sobrecarga operacional  

üìç **Quando escolher?**  
- Se quer uma solu√ß√£o **pronta e f√°cil** de usar  
- Se j√° usa **Vertex AI**  
- Se **n√£o quer gerenciar Kubernetes**  

---

## üõ†Ô∏è Kubeflow Pipelines no GKE
‚úÖ **Autogerenciado no Kubernetes** (GKE)  
‚úÖ **Mais flex√≠vel** e personaliz√°vel  
‚úÖ **Menor custo** para workloads grandes  
‚úÖ **Poss√≠vel uso h√≠brido/multicloud**  

üìç **Quando escolher?**  
- Se precisa de **controle total sobre a infraestrutura**  
- Se j√° tem **expertise em Kubernetes**  
- Se quer **rodar workloads h√≠bridos**  

---

## üî• Compara√ß√£o r√°pida

| Caracter√≠stica          | **Vertex AI Pipelines** | **Kubeflow Pipelines (GKE)** |
|------------------------|-----------------------|-----------------------------|
| **Gerenciamento**      | Autom√°tico (GCP)      | Manual (Kubernetes)        |
| **Infraestrutura**     | Oculta                | GKE gerenciado pelo usu√°rio |
| **Integra√ß√£o GCP**     | Total (Vertex AI, IAM, Logging) | Parcial |
| **Flexibilidade**      | Menor                  | Alta (customiz√°vel)        |
| **Escalabilidade**     | Autom√°tica             | Controlada pelo usu√°rio    |
| **Seguran√ßa (IAM)**    | Integrada com GCP      | Definida pelo usu√°rio      |
| **Custo**              | Paga conforme uso      | Pode ser mais barato em alto volume |

### üöÄ **Recomenda√ß√£o**
- **Vertex AI Pipelines** ‚Üí Para produtividade, facilidade e integra√ß√£o com GCP  
- **Kubeflow Pipelines (GKE)** ‚Üí Para flexibilidade, personaliza√ß√£o e workloads h√≠bridos  
  
- Explique como voc√™ estruturaria uma infraestrutura escal√°vel para treinar e servir modelos de ML na GCP.
  # Resposta: üöÄ Infraestrutura Escal√°vel para ML na GCP

## üîπ **Arquitetura Geral**
A infraestrutura deve permitir **treinamento escal√°vel**, **armazenamento eficiente**, **servi√ßo de infer√™ncia otimizado** e **monitoramento cont√≠nuo**.  

---

## üî• **1. Treinamento Escal√°vel**
### ‚úÖ **Gerenciamento de Dados**
- **Cloud Storage (GCS)** ‚Üí Armazena datasets grandes  
- **BigQuery** ‚Üí Para an√°lise e manipula√ß√£o de dados estruturados  
- **Feature Store (Vertex AI)** ‚Üí Gerencia features reutiliz√°veis  

### ‚úÖ **Treinamento Distribu√≠do**
- **Vertex AI Training** ‚Üí Escal√°vel, suporta GPUs/TPUs  
- **Dataflow** ‚Üí Para pr√©-processamento distribu√≠do  
- **Kubeflow Pipelines** / **Vertex AI Pipelines** ‚Üí Automa√ß√£o de workflows  

### ‚úÖ **Gerenciamento de Experimentos**
- **Vertex AI Experiments** ‚Üí Rastreamento autom√°tico  
- **MLflow** (Self-hosted no GKE) ‚Üí Alternativa customiz√°vel  

---

## ‚ö° **2. Implanta√ß√£o e Servir Modelos**
### ‚úÖ **Op√ß√µes de Deployment**
- **Vertex AI Endpoints** ‚Üí Modelo gerenciado, autoescal√°vel  
- **Cloud Run** ‚Üí Para modelos leves via API  
- **GKE (Kubernetes Engine)** ‚Üí Para infer√™ncia customizada e de alto volume  

### ‚úÖ **Otimiza√ß√£o de Infer√™ncia**
- **Vertex AI Prediction** ‚Üí Autoescal√°vel, otimizado para GPUs/TPUs  
- **TF Serving / TorchServe no GKE** ‚Üí Para arquiteturas customizadas  
- **Redis / Memorystore** ‚Üí Cache para previs√µes frequentes  

---

## üìä **3. Monitoramento e Observabilidade**
- **Vertex AI Model Monitoring** ‚Üí Detecta drift de dados  
- **Cloud Logging & Monitoring** ‚Üí Para logs e m√©tricas  
- **Prometheus + Grafana (GKE)** ‚Üí Para monitoramento customizado  

---

## üéØ **Resumo da Infraestrutura**
| Componente         | Tecnologia (GCP)                        |
|--------------------|----------------------------------------|
| **Armazenamento**  | Cloud Storage, BigQuery, Feature Store |
| **Treinamento**    | Vertex AI Training, Dataflow, Pipelines |
| **Servi√ßo de ML**  | Vertex AI Endpoints, Cloud Run, GKE     |
| **Monitoramento**  | Model Monitoring, Logging, Prometheus  |

### üöÄ **Conclus√£o**
- Para **simplicidade e escalabilidade**, use **Vertex AI**.  
- Para **customiza√ß√£o**, use **GKE + Kubeflow**.  
- Para **infer√™ncia otimizada**, combine **GPU/TPU + caching**.  

### 2. CI/CD para Machine Learning  
- Como voc√™ implementaria uma pipeline CI/CD para modelos de ML na GCP utilizando Cloud Build, Vertex AI e Terraform?
  # Resposta: üöÄ CI/CD para Modelos de ML na GCP com Cloud Build, Vertex AI e Terraform

Uma **pipeline CI/CD** para modelos de ML na GCP precisa automatizar **treinamento, valida√ß√£o, implanta√ß√£o e monitoramento**. Abaixo est√° uma estrutura escal√°vel usando **Cloud Build**, **Vertex AI** e **Terraform**.

---

## üìå **1. Estrutura da Pipeline**
### ‚úÖ **Infraestrutura como C√≥digo (IaC)**
- **Terraform** ‚Üí Provisiona os recursos na GCP (**Bucket, Vertex AI, IAM, GKE, etc.**)

### ‚úÖ **Treinamento e Valida√ß√£o**
- **Cloud Build** ‚Üí Executa pipelines de ML  
- **Vertex AI Training** ‚Üí Treinamento distribu√≠do (GPUs/TPUs)  
- **Cloud Storage** ‚Üí Armazena datasets e artefatos  
- **Vertex AI Experiments** ‚Üí Registro de experimentos  

### ‚úÖ **Implanta√ß√£o e Monitoramento**
- **Cloud Build + Vertex AI Endpoints** ‚Üí Servir modelos  
- **Cloud Run** ‚Üí Alternativa para API leve  
- **Vertex AI Model Monitoring** ‚Üí Detecta drift de dados  
- **Cloud Logging & Monitoring** ‚Üí Coleta logs e m√©tricas  

---

## üî• **2. Fluxo da Pipeline**
```mermaid
graph TD;
  DevOps["üë®‚Äçüíª Dev/ML Engineer"] -->|Code Commit| GitHub/GitLab
  GitHub/GitLab -->|Trigger| Cloud Build
  Cloud Build -->|Terraform Apply| GCP Infra
  Cloud Build -->|Train Model| Vertex AI Training
  Vertex AI Training -->|Store Artifacts| Cloud Storage
  Cloud Build -->|Validate Model| Vertex AI Experiments
  Vertex AI Experiments -->|Pass? Yes| Deploy
  Deploy -->|Vertex AI Endpoints| Serving
  Deploy -->|Cloud Run| API (Alternative)
  Serving -->|Monitor| Vertex AI Model Monitoring
  Serving -->|Logs| Cloud Logging
```
- Explique como gerenciar versionamento de modelos no Vertex AI Model Registry e como reverter um modelo para uma vers√£o anterior.
# Resposta: üìå Gerenciamento de Versionamento de Modelos no Vertex AI Model Registry

O **Vertex AI Model Registry** permite armazenar, versionar e gerenciar modelos de ML na GCP, facilitando controle de vers√µes e rollback.

---

## üîπ **1. Como Versionar um Modelo no Vertex AI**
Cada vez que um modelo √© atualizado, o Vertex AI cria uma **nova vers√£o** dentro do mesmo registro.

### ‚úÖ **Registrar um Novo Modelo**
```bash
gcloud ai models upload \
  --region=us-central1 \
  --display-name=my-model \
  --artifact-uri=gs://ml-models-bucket/model-v1 \
  --container-image-uri=gcr.io/cloud-aiplatform/prediction/tf2-cpu
```
Isso cria version 1 do modelo.

gcloud ai models upload \
  --region=us-central1 \
  --display-name=my-model \
  --version-aliases=v2 \
  --artifact-uri=gs://ml-models-bucket/model-v2
Isso adiciona a version 2 ao modelo existente.

Para visualizar todas as vers√µes registradas:
gcloud ai models list --region=us-central1

Para ver detalhes de um modelo espec√≠fico:
gcloud ai models describe my-model --region=us-central1

Caso a nova vers√£o tenha problemas, √© poss√≠vel reverter para uma vers√£o est√°vel.
Desativar a vers√£o problem√°tica (exemplo: version 2):

gcloud ai models versions delete v2 \
  --model=my-model \
  --region=us-central1

Reimplantar uma vers√£o anterior (exemplo: version 1):
gcloud ai endpoints deploy-model \
  --model=my-model \
  --deployed-model-display-name=my-model-v1 \
  --region=us-central1 \
  --traffic-split=0=100

### 3. Monitoramento e Observabilidade  
- Como monitorar um modelo de ML em produ√ß√£o na GCP para detectar desvio de conceito (concept drift)?  
- Quais m√©tricas-chave voc√™ acompanharia para garantir a performance e confiabilidade de um modelo implantado no Vertex AI?  

### 4. Seguran√ßa e Compliance  
- Como garantir a seguran√ßa e privacidade dos dados ao treinar modelos na GCP? Quais servi√ßos da GCP voc√™ utilizaria?  
- Quais pr√°ticas de controle de acesso voc√™ aplicaria para proteger pipelines de treinamento e infer√™ncia na GCP?  
